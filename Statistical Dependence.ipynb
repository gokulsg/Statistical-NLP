{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name : Gokul Srinivasagan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointwise mutual information (PMI)\n",
    "\n",
    "### The pointwise mutual information is a quantified measure of how much more or less likely we can see the two events co-occur, given their individual probabilities, and relative to the case where the two are completely independent.  PMI is used for finding associations between words.  This is calculated by using the formula,\n",
    "\n",
    "$$\n",
    "pmi(w1 , w2) = log(\\frac{C(w1 w2)*N)}{(C(w1)*C(w2)})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, The program start with the preprocessing step where it tokenize the words and retain only the alphabetic tokens. (All the punctualtions would be eliminated). Then it removes the words whose occurance is less than 10 in the corpus. Then the pmi score is computed for the word pairs in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ngram import *\n",
    "import nltk\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tokens(file_name):\n",
    "    \"\"\"\n",
    "    Generate tokens by processing the input file\n",
    "\n",
    "    Args:\n",
    "        file_name (string): file to be processed\n",
    "        \n",
    "    Returns:\n",
    "        word_tokens(list): list of word obtained after word tokenization\n",
    "    \"\"\"\n",
    "    file = open(file_name, 'r', encoding='utf-8').read()\n",
    "    word_tokens = nltk.word_tokenize(file)\n",
    "    # Remove punctuations, keeping only the words and convert into smaller case #\n",
    "    # Ref : https://stackoverflow.com/questions/15547409/how-to-get-rid-of-punctuation-using-nltk-tokenizer #\n",
    "    word_tokens=[word.lower() for word in word_tokens if word.isalpha()]\n",
    "    return word_tokens\n",
    "\n",
    "def remove_words_frequency(word_tokens, freq = 10):\n",
    "    \"\"\"\n",
    "    Remove the words whose frequency is less than the specified value\n",
    "\n",
    "    Args:\n",
    "        word_tokens (list): list of tokens obtained from the file\n",
    "        freq (int) : the frequency threshold value. Words having freruency below this value will be eliminated\n",
    "    \n",
    "     Returns:\n",
    "        (list): list of word having freruency above the specified value\n",
    "    \"\"\"\n",
    "    \n",
    "    # removing words that have a frequency less than the certain value #\n",
    "    return [ i for i in word_tokens if word_tokens.count(i) > freq]\n",
    "    \n",
    "\n",
    "def pmi(word_pair, num_word_tokens, freq_dict):\n",
    "    \"\"\"\n",
    "    Calculate the pmi score for the word pairs\n",
    "\n",
    "    Args:\n",
    "        word_pair (tuple): word pair (w1,w2)\n",
    "        num_word_tokens (int) : Number of words in the corpus after removing the least occuring words\n",
    "        freq_dict (Dict) : Dictionary with the frequecy of words and word pairs\n",
    "        \n",
    "    Returns:\n",
    "        (float): pmi score\n",
    "    \"\"\"\n",
    "    Cw1 = freq_dict.get(word_pair[0])\n",
    "    Cw2 = freq_dict.get(word_pair[1])\n",
    "    Cw1w2 = freq_dict.get(word_pair)\n",
    "\n",
    "    return math.log(((Cw1w2 * num_word_tokens))/(Cw1 * Cw2))\n",
    "\n",
    "def compute_pmi_values(freq_dict, word_pairs, num_word_tokens):\n",
    "    \"\"\"\n",
    "    Compute pmi value for all the word pairs\n",
    "\n",
    "    Args:\n",
    "        word_pairs (list): list of all word pair (w1,w2)\n",
    "        num_word_tokens (int) : Number of words in the corpus after removing the least occuring words\n",
    "        freq_dict (Dict) : Dictionary with the frequecy of words and word pairs\n",
    "        \n",
    "    Returns:\n",
    "        pmi_dict(Dict): Dictionary where key is word pair and value is pmi score\n",
    "    \"\"\"\n",
    "    # A dictionary with word pairs initialized with zero #\n",
    "    pmi_dict = dict.fromkeys(word_pairs,0)\n",
    "    for word_pair in pmi_dict.keys():\n",
    "        pmi_score = pmi(word_pair, num_word_tokens, freq_dict)\n",
    "        pmi_dict[word_pair] = pmi_score\n",
    "    return pmi_dict\n",
    "\n",
    "def display_result(output_dict, range_val = 20):\n",
    "    \"\"\"\n",
    "    Display the result in tabulat format\n",
    "\n",
    "    Args:\n",
    "        output_dict (list): Dictionary where key is word pair and value is pmi score\n",
    "        range_val (int) : Number of entries to be present on the table\n",
    "    \"\"\"\n",
    "    # If the specified range_val is larger than the length of dictionary, it is made to maximum length of the dictionary#\n",
    "    if range_val > len(output_dict):\n",
    "        range_val = len(output_dict)\n",
    "    # Ref: https://www.geeksforgeeks.org/python-get-first-n-keyvalue-pairs-in-given-dictionary/ #\n",
    "    # Ref: https://www.educba.com/python-print-table/#\n",
    "    result = dict(list(output_dict.items())[0: range_val])\n",
    "    line = '-' * 50\n",
    "    print(line)\n",
    "    print('{:<15s}{:<15s}{:>10s}'.format(\"w1\", \"w2\", \"pmi\"))\n",
    "    print(line)\n",
    "    for key, value in result.items():\n",
    "        print('{:<15s}{:<15s}{:>10s}'.format(key[0], key[1], str(format(value, \".5f\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"junglebook.txt\"\n",
    "word_tokens = generate_tokens(filename)\n",
    "word_tokens = remove_words_frequency(word_tokens)\n",
    "num_word_tokens = len(word_tokens)\n",
    "\n",
    "# Generating the token pairs ( C(w1,w2) ) #\n",
    "# Ref : https://stackoverflow.com/questions/17531684/n-grams-in-python-four-five-six-grams #\n",
    "word_pairs = list(nltk.ngrams(word_tokens, 2))\n",
    "\n",
    "# finding the frequency distribution by combining the list of individual words and  word pairs #\n",
    "freq_dict = nltk.FreqDist(word_tokens + word_pairs)\n",
    "\n",
    "pmi_dict = compute_pmi_values(freq_dict, word_pairs, num_word_tokens)\n",
    "\n",
    "# Sorting dictionary in descending order of frequency #\n",
    "pmi_dict_sort = dict(sorted(pmi_dict.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 word pairs with the highest pmi value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "w1             w2                    pmi\n",
      "--------------------------------------------------\n",
      "machua         appa              8.28885\n",
      "literary       archive           8.12180\n",
      "archive        foundation        7.46787\n",
      "gutenberg      literary          7.28555\n",
      "petersen       sahib             7.13140\n",
      "hind           legs              6.98017\n",
      "fore           paws              6.90256\n",
      "hind           flippers          6.88009\n",
      "twenty         yoke              6.84194\n",
      "electronic     works             6.69777\n",
      "master         words             6.66140\n",
      "years          ago               6.63323\n",
      "within         days              6.61772\n",
      "bring          news              6.61488\n",
      "council        rock              6.49391\n",
      "black          panther           6.48955\n",
      "darzee         wife              6.43825\n",
      "villagers      lived             6.41705\n",
      "moon           rose              6.39173\n",
      "brown          bear              6.37372\n"
     ]
    }
   ],
   "source": [
    "display_result(pmi_dict_sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The PMI quantify the likelihood of co-occurrence of two words, taking into account the fact that it might be caused by the frequency of the single words. Positive PMI says the words co-occur more frequently than would be expected under an independence assumption, and negative PMI means the words co-occur less frequently than would be expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These words with higher PMI score has the highest chances of co-occuring in pairs. For example, literary archive is commonly found as pairs. In other words, PMI value maximises when the two words are perfectly associated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 word pairs with the lowest pmi value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "w1             w2                    pmi\n",
      "--------------------------------------------------\n",
      "he             of               -3.51190\n",
      "little         the              -3.02141\n",
      "the            a                -2.99193\n",
      "the            be               -2.86933\n",
      "a              his              -2.86873\n",
      "of             was              -2.80860\n",
      "a              was              -2.66772\n",
      "the            not              -2.61801\n",
      "said           of               -2.61020\n",
      "to             of               -2.56389\n",
      "the            no               -2.55389\n",
      "in             in               -2.54270\n",
      "and            is               -2.52343\n",
      "of             they             -2.47213\n",
      "i              and              -2.45043\n",
      "is             he               -2.44615\n",
      "his            the              -2.41789\n",
      "of             he               -2.41329\n",
      "to             they             -2.41011\n",
      "a              the              -2.40414\n"
     ]
    }
   ],
   "source": [
    "# Sorting dictionary in Ascending order of frequency  - For getting the words with lowest pmi values #\n",
    "pmi_dict_sort_ascending = dict(sorted(pmi_dict.items(), key=lambda item: item[1]))\n",
    "display_result(pmi_dict_sort_ascending)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table, we can see that the words with negative pmi score don't carry any meaningful information if they co-occur like he of, little the."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional work - For bible corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"kingjamesbible_tokenized.txt\"\n",
    "word_tokens = generate_tokens(filename)\n",
    "word_tokens = remove_words_frequency(word_tokens)\n",
    "num_word_tokens = len(word_tokens)\n",
    "\n",
    "# Generating the token pairs ( C(w1,w2) ) #\n",
    "# Ref : https://stackoverflow.com/questions/17531684/n-grams-in-python-four-five-six-grams #\n",
    "word_pairs = list(nltk.ngrams(word_tokens, 2))\n",
    "\n",
    "# finding the frequency distribution by combining the list of individual words and  word pairs #\n",
    "freq_dict = nltk.FreqDist(word_tokens + word_pairs)\n",
    "\n",
    "pmi_dict = compute_pmi_values(freq_dict, word_pairs, num_word_tokens)\n",
    "\n",
    "# Sorting dictionary in descending order of frequency #\n",
    "pmi_dict_sort = dict(sorted(pmi_dict.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 word pairs with the highest pmi value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "w1             w2                    pmi\n",
      "--------------------------------------------------\n",
      "shadrach       meshach          10.76875\n",
      "badgers        skins            10.29363\n",
      "ill            favoured          9.99045\n",
      "judas          iscariot          9.95398\n",
      "brook          kidron            9.68156\n",
      "jonas          lovest            9.67460\n",
      "measuring      reed              9.59730\n",
      "divers         colours           9.52941\n",
      "mary           magdalene         9.46980\n",
      "precept        precept           9.44315\n",
      "overflowing    scourge           9.35614\n",
      "shem           ham               9.26566\n",
      "duke           duke              9.24227\n",
      "fiery          furnace           9.22831\n",
      "sharp          sickle            9.22831\n",
      "committeth     adultery          9.21506\n",
      "beriah         heber             9.20199\n",
      "perpetual      desolations       9.20199\n",
      "golden         spoon             9.17382\n",
      "bright         spot              9.15685\n"
     ]
    }
   ],
   "source": [
    "display_result(pmi_dict_sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 word pairs with the lowest pmi value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "w1             w2                    pmi\n",
      "--------------------------------------------------\n",
      "his            the              -5.87115\n",
      "the            him              -5.63023\n",
      "the            them             -5.59524\n",
      "the            it               -5.54729\n",
      "thy            of               -5.34012\n",
      "the            thy              -5.26032\n",
      "the            i                -5.22198\n",
      "of             have             -5.17606\n",
      "and            son              -5.08722\n",
      "the            we               -5.03935\n",
      "of             not              -5.03489\n",
      "the            not              -4.95509\n",
      "and            house            -4.92017\n",
      "unto           of               -4.91234\n",
      "that           lord             -4.90280\n",
      "of             thou             -4.82092\n",
      "unto           he               -4.81033\n",
      "the            my               -4.80310\n",
      "in             be               -4.75648\n",
      "and            land             -4.75626\n"
     ]
    }
   ],
   "source": [
    "# Sorting dictionary in Ascending order of frequency  - For getting the words with lowest pmi values #\n",
    "pmi_dict_sort_ascending = dict(sorted(pmi_dict.items(), key=lambda item: item[1]))\n",
    "display_result(pmi_dict_sort_ascending)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution time for bible corpus is 137 minutes "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
